{
    "base_model_name": "mistralai/Mistral-7B-v0.1",
    "lora_config": {
        "r": 8,
        "lora_alpha": 16,
        "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj"],
        "lora_dropout": 0.05,
        "bias": "none",
        "task_type": "CAUSAL_LM"
    },
    "load_in_8bit": true,
    "device_map": "auto",
    "torch_dtype": "float16"
} 