{
    "base_model_name": "codellama/CodeLlama-7b-Instruct-hf",
    "lora_config": {
        "r": 32,
        "lora_alpha": 64,
        "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
        "lora_dropout": 0.1,
        "bias": "none",
        "task_type": "CAUSAL_LM"
    },
    "load_in_4bit": true,
    "bnb_config": {
        "load_in_4bit": true,
        "bnb_4bit_use_double_quant": true,
        "bnb_4bit_quant_type": "nf4",
        "bnb_4bit_compute_dtype": "bfloat16"
    },
    "device_map": "auto",
    "torch_dtype": "bfloat16"
} 