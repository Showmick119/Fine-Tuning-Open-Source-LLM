{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Showmick119/Fine-Tuning-Open-Source-LLM/blob/main/notebooks/2_test_finetuned.ipynb)\n",
        "\n",
        "# üß™ Testing Fine-tuned CodeLlama\n",
        "\n",
        "This notebook demonstrates how to use your fine-tuned **CodeLlama-7b-Instruct** model for code generation. We'll load the model with the trained LoRA adapter and test it with various coding prompts.\n",
        "\n",
        "## üéØ What You'll Test\n",
        "\n",
        "- Code generation capabilities\n",
        "- Different programming languages\n",
        "- Algorithm implementations\n",
        "- Code explanation and debugging\n",
        "- Interactive prompt testing\n",
        "\n",
        "## üîß Setup\n",
        "\n",
        "First, let's install the required packages and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q torch transformers peft bitsandbytes accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### üì¶ Import Dependencies\n",
        "\n",
        "Let's import our text generation module and other required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('.')\n",
        "\n",
        "from inference.generate_text import TextGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ü§ñ Initialize Text Generator\n",
        "\n",
        "Now let's initialize our text generator with the fine-tuned **CodeLlama** model. Make sure the `adapter_path` points to your trained LoRA adapter from the previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ Initialize the CodeLlama text generator with fine-tuned adapter\n",
        "print(\"ü§ñ Loading fine-tuned CodeLlama model...\")\n",
        "\n",
        "generator = TextGenerator(\n",
        "    base_model_name=\"codellama/CodeLlama-7b-Instruct-hf\",\n",
        "    adapter_path=\"outputs/checkpoints\",  # Path to your fine-tuned LoRA adapter\n",
        "    device=\"auto\",\n",
        "    load_8bit=True,  # Use 8-bit for efficiency\n",
        "    temperature=0.2  # Lower temperature for more focused code generation\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "# Check GPU memory usage\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üíæ GPU Memory Used: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üêç Test Python Code Generation\n",
        "\n",
        "Let's start by testing the model's ability to generate Python code with a simple algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üêç Test Python algorithm generation\n",
        "instruction = \"Write a Python function to implement binary search in a sorted array\"\n",
        "response = generator.generate(\n",
        "    instruction=instruction,\n",
        "    max_new_tokens=300,\n",
        "    temperature=0.1  # Very focused generation\n",
        ")\n",
        "\n",
        "print(\"üéØ Generated Python Code:\")\n",
        "print(\"=\" * 50)\n",
        "print(response)\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üåê Test Multiple Programming Languages\n",
        "\n",
        "Let's test the model's versatility across different programming languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üåê Test different programming languages\n",
        "programming_tasks = [\n",
        "    \"Write a JavaScript function to validate an email address\",\n",
        "    \"Create a Java class for a simple calculator with basic operations\",\n",
        "    \"Write a C++ function to find the factorial of a number using recursion\"\n",
        "]\n",
        "\n",
        "print(\"üåê Testing Multiple Programming Languages:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, instruction in enumerate(programming_tasks, 1):\n",
        "    print(f\"\\nüî• Task {i}: {instruction}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    response = generator.generate(\n",
        "        instruction=instruction,\n",
        "        max_new_tokens=250,\n",
        "        temperature=0.1\n",
        "    )\n",
        "    \n",
        "    print(response)\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üêõ Test Code Debugging & Explanation\n",
        "\n",
        "Let's test the model's ability to debug code and provide explanations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üêõ Test code debugging\n",
        "instruction = \"Find and fix the bug in this Python code\"\n",
        "buggy_code = \"\"\"\n",
        "def fibonacci(n):\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    else:\n",
        "        return fibonacci(n-1) + fibonacci(n-2)\n",
        "\n",
        "# This should print the first 10 fibonacci numbers\n",
        "for i in range(10):\n",
        "    print(f\"F({i}) = {fibonacci(i)}\")\n",
        "\"\"\"\n",
        "\n",
        "response = generator.generate(\n",
        "    instruction=instruction,\n",
        "    input_text=buggy_code,\n",
        "    max_new_tokens=300\n",
        ")\n",
        "\n",
        "print(\"üêõ Code Debugging Results:\")\n",
        "print(\"=\" * 50)\n",
        "print(response)\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéõÔ∏è Interactive Testing Interface\n",
        "\n",
        "Create your own prompts and test the model interactively! Try different types of coding tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéõÔ∏è Interactive testing function\n",
        "def test_custom_prompt():\n",
        "    \"\"\"Interactive function to test custom prompts\"\"\"\n",
        "    print(\"üéØ Custom Prompt Testing\")\n",
        "    print(\"Enter your coding instruction (or type 'quit' to exit):\")\n",
        "    \n",
        "    while True:\n",
        "        instruction = input(\"\\nüí≠ Your instruction: \")\n",
        "        \n",
        "        if instruction.lower() == 'quit':\n",
        "            break\n",
        "            \n",
        "        print(f\"\\nü§ñ Generating code for: {instruction}\")\n",
        "        print(\"‚è≥ Please wait...\")\n",
        "        \n",
        "        response = generator.generate(\n",
        "            instruction=instruction,\n",
        "            max_new_tokens=400,\n",
        "            temperature=0.1\n",
        "        )\n",
        "        \n",
        "        print(\"\\nüéØ Generated Code:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(response)\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "# Uncomment the line below to run interactive testing\n",
        "# test_custom_prompt()\n",
        "\n",
        "# Example prompts you can try:\n",
        "example_prompts = [\n",
        "    \"Write a Python function to implement merge sort\",\n",
        "    \"Create a REST API endpoint using Flask\",\n",
        "    \"Write a SQL query to find the top 5 customers by sales\",\n",
        "    \"Implement a linked list in Python with insert and delete methods\",\n",
        "    \"Write a function to check if a string is a palindrome\"\n",
        "]\n",
        "\n",
        "print(\"üéØ Example prompts you can try:\")\n",
        "for i, prompt in enumerate(example_prompts, 1):\n",
        "    print(f\"{i}. {prompt}\")\n",
        "\n",
        "print(\"\\nüí° To test interactively, uncomment the test_custom_prompt() call above!\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
